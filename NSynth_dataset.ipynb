{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSynth dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claree007/Housing-Prices/blob/master/NSynth_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yakjDB5l64ix",
        "colab_type": "text"
      },
      "source": [
        "<h1>California Housing Prices</h1>\n",
        "\n",
        "This is a regression problem which I have tackled using different ML models and here I compare their training time and accuracy. I have used Scikit-Learn and TensorFlow.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msJ_fxf6w9UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.base import BaseEstimator, TransformerMixin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEYDNJEr7xKx",
        "colab_type": "text"
      },
      "source": [
        "<h2>Loading the dataset</h2>\n",
        "\n",
        "The dataset is already split into train and test set but it is the ratio 1:1. So I combine the 2 sets and then divide the whole set into train and test sets in the ratio 80 : 20 and then split the training set to make validation set in the ratio 20 : 80. The dataset is already clean and ready to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7S7Fq3i3LLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HOUSING_PATH = \"sample_data\"\n",
        "\n",
        "def load_housing_data(file_name, housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, file_name)\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "housing_set1 = load_housing_data(file_name=\"california_housing_train.csv\")\n",
        "housing_set2 = load_housing_data(file_name=\"california_housing_test.csv\")\n",
        "\n",
        "housing = pd.concat([housing_set1, housing_set2], axis=0, ignore_index=True)\n",
        "\n",
        "housing_X = housing.drop(\"median_house_value\", axis=1)\n",
        "housing_y = housing[\"median_house_value\"].copy()\n",
        "\n",
        "X_train_whole, X_test, y_train_whole, y_test = train_test_split(housing_X, housing_y, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_whole, y_train_whole, test_size=0.2)\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Test set size:\", X_test.shape)\n",
        "\n",
        "housing.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9dzx1QR-0__",
        "colab_type": "text"
      },
      "source": [
        "Some visualizations of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ex9VFypLCO-T",
        "colab_type": "code",
        "outputId": "78767e19-5e03-4f63-c689-240c70148441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#housing.hist(bins=50, figsize=(20, 15))\n",
        "#plt.show()\n",
        "\n",
        "correlation = housing.corr()\n",
        "correlation[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "median_house_value    1.000000\n",
              "median_income         0.689109\n",
              "total_rooms           0.135298\n",
              "housing_median_age    0.104470\n",
              "households            0.066573\n",
              "total_bedrooms        0.051111\n",
              "population           -0.024234\n",
              "longitude            -0.045788\n",
              "latitude             -0.143969\n",
              "Name: median_house_value, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eYuPFh2XBOyH"
      },
      "source": [
        "<h2>Training</h2>\n",
        "\n",
        "For each model, the best hyperparameters will searched and used. The accuracy of each model during training is testd against a validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQlXApY_aHOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmse_error(y_train, y_train_predict, y_val, y_val_predict):\n",
        "    train_error = []\n",
        "    val_error = []\n",
        "    '''\n",
        "    for i in range(len(y_train)):\n",
        "        train_error.append(mean_squared_error(y_train.iloc[:i+1], y_train_predict[:i+1]))\n",
        "    for i in range(len(y_val)):\n",
        "        val_error.append(mean_squared_error(y_val.iloc[:i+1], y_val_predict[:i+1]))\n",
        "    '''\n",
        "    train_error = np.sqrt(mean_squared_error(y_train, y_train_predict))\n",
        "    val_error = np.sqrt(mean_squared_error(y_val, y_val_predict))\n",
        "    return train_error, val_error\n",
        "    '''\n",
        "    plt.plot(np.sqrt(train_error), \"b-\", linewidth=2, label=\"train\")\n",
        "    plt.plot(np.sqrt(val_error), \"r-\", linewidth=2, label=\"validation\")\n",
        "    plt.legend()\n",
        "    '''\n",
        "\n",
        "def cross_validation_score(X, y):\n",
        "    scores = cross_val_score(model, X, y, cv=10)\n",
        "    \n",
        "def train_model(model, X_t, y_t, X_v, y_v):\n",
        "    # \n",
        "    print(model)\n",
        "    start = time.time()\n",
        "    model.fit(X, y_train_whole)\n",
        "    end = time.time()\n",
        "    \n",
        "    y_train_predict = elastic_net.predict(X_train)\n",
        "    y_val_predict = elastic_net.predict(X_val)\n",
        "\n",
        "    rmse_error(y_train.values, y_train_predict, y_val.values, y_val_predict)\n",
        "\n",
        "    scores = cross_validation_score(lin_reg, X_train_whole, y_train_whole)\n",
        "    print(\"Accuracy: {0:2.2f} +/- {1:2.2f}\".format(scores.mean(), scores.std()))\n",
        "    print(\"Time taken:\", end-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGOBuiwTkMBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the bias term to training set\n",
        "X_train_bias = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
        "\n",
        "# add bais term to validation set\n",
        "X_val_bias = np.c_[np.ones((X_val.shape[0], 1)), X_val]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HABSOFB4_6WM",
        "colab_type": "text"
      },
      "source": [
        "<h3>Linear Regression</h3>\n",
        "\n",
        "1. Normal Equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwfdTv0YrjAw",
        "colab_type": "code",
        "outputId": "d0d91e0c-1f92-4248-dd9c-d1655cdfd40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "\n",
        "#print(X_train_bias)\n",
        "theta_best = np.linalg.inv(X_train_bias.T.dot(X_train_bias)).dot(X_train_bias.T).dot(y_train)\n",
        "\n",
        "y_train_predict = X_train_bias.dot(theta_best)\n",
        "\n",
        "# making predictions\n",
        "\n",
        "y_val_predict = X_val_bias.dot(theta_best)\n",
        "\n",
        "rmse_error(y_train, y_train_predict, y_val, y_val_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[196753.96271378 253776.39096495 275686.67553636 ... 240420.82852495\n",
            " 113908.62704181 555415.63074914]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69262.10859781038, 69052.37608887155)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riC3x1hNYEjI",
        "colab_type": "text"
      },
      "source": [
        "2. Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqs1CdNbYIRl",
        "colab_type": "code",
        "outputId": "161116cf-9d9c-417b-de3b-ca7e005a6a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "lr = 0.3\n",
        "n_iterations = 150\n",
        "m = X_train.shape[0]\n",
        "\n",
        "theta = np.random.randn(X_train.shape[1]+1, 1)\n",
        "cost = np.array([])\n",
        "std_scaler = StandardScaler()\n",
        "X_train_bias = std_scaler.fit_transform(X_train_bias)\n",
        "#print(X_train_bias.dot(theta))\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    #print(X_train_bias.dot(theta))\n",
        "    #print(iteration,)\n",
        "    #y_train.reshape = (-1, 1)\n",
        "    y_train.values.shape = (y_train.shape[0], 1)\n",
        "    err = np.subtract(X_train_bias.dot(theta), y_train.values)\n",
        "    #print(X_train_bias.dot(theta).shape, y_train.shape, err.shape)\n",
        "    cost = np.append(cost, (1 / (2 * m)) * np.sum(np.square(err)))\n",
        "    #print(\"cost:\", cost[iteration])\n",
        "    gradient = (1 / m) * (X_train_bias.T.dot(err))\n",
        "    #print(\"gradient:\", gradient)\n",
        "    #print(X_train_bias.T.shape, err.shape, (X_train_bias.T.dot(err)).shape)\n",
        "    theta = theta - (lr * gradient)\n",
        "    #print(\"theta:\", theta)\n",
        "    \n",
        "plt.plot(np.arange(1, n_iterations + 1), cost, \"b-\", label=\"cost function\")\n",
        "plt.xlabel(\"no of iterations\")\n",
        "plt.ylabel(\"cost\")\n",
        "plt.show()\n",
        "\n",
        "y_train_predict = X_train_bias.dot(theta)\n",
        "y_val_predict = X_val_bias.dot(theta)\n",
        "#print(y_train.values, y_train_predict)\n",
        "rmse_error(y_train.values, y_train_predict, y_val.values, y_val_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218593.23477222692, 93681217.32775296)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEhdsJetsWqT",
        "colab_type": "text"
      },
      "source": [
        "3. Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eDAOw8TzEEb",
        "colab_type": "code",
        "outputId": "5706a136-e26a-4e0e-e9b8-0d8729493f1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.03)\n",
        "sgd_reg.fit(X_train_bias, y_train.ravel())\n",
        "\n",
        "y_train_predict = sgd_reg.predict(X_train_bias)\n",
        "y_val_predict = sgd_reg.predict(X_val_bias)\n",
        "\n",
        "rmse_error(y_train.values, y_train_predict, y_val.values, y_val_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2028073076128049.0, 2043520310561359.2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzdn3xhl3tVg",
        "colab_type": "text"
      },
      "source": [
        "4. Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gjDmLNn3zPs",
        "colab_type": "code",
        "outputId": "6cfef615-91f3-4695-ed5f-a087355a85e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ridge_reg = Ridge(alpha=1, solver=\"cholesky\")\n",
        "ridge_reg.fit(X_train, y_train.ravel())\n",
        "\n",
        "y_train_predict = ridge_reg.predict(X_train)\n",
        "y_val_predict = ridge_reg.predict(X_val)\n",
        "\n",
        "rmse_error(y_train.values, y_train_predict, y_val.values, y_val_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69262.10914904466, 69052.6120658872)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j88Dby-5cHB",
        "colab_type": "text"
      },
      "source": [
        "5. Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMZOm7lS5gQ0",
        "colab_type": "code",
        "outputId": "e8346cbd-d795-43b0-a9a7-111acfbfe01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lasso_reg = Lasso(alpha=0.1)\n",
        "lasso_reg.fit(X_train, y_train.ravel())\n",
        "\n",
        "y_train_predict = lasso_reg.predict(X_train)\n",
        "y_val_predict = lasso_reg.predict(X_val)\n",
        "\n",
        "rmse_error(y_train.values, y_train_predict, y_val.values, y_val_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69262.10859831468, 69052.38359630929)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jibJhP027Jvb",
        "colab_type": "text"
      },
      "source": [
        "6. Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzGIHv4T7Mwu",
        "colab_type": "code",
        "outputId": "3a58f65e-8f76-4fa5-c620-e7e09956e6d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "elastic_net.fit(X_train, y_train.ravel())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69422.92461676648, 69336.57644675748)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzJCfNNc8zwU",
        "colab_type": "text"
      },
      "source": [
        "7. Polynomial Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl4nsXrz84ME",
        "colab_type": "code",
        "outputId": "f1cf275f-8355-4b56-c254-506025453882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "poly_features = PolynomialFeatures(degree=2, include_bias=\"False\")\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_val_poly = poly_features.transform(X_val)\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_poly, y_train.ravel())\n",
        "\n",
        "y_train_predict = lin_reg.predict(X_train_poly)\n",
        "y_val_predict = lin_reg.predict(X_val_poly)\n",
        "\n",
        "rmse_error(y_train.values, y_train_predict, y_val.values, y_val_predict)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62911.05336098876, 62825.81707574824)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XSNLcBnEPqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lin_reg = LinearRegression()\n",
        "train_model(lin_reg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeNXwjMU6Xgx",
        "colab_type": "code",
        "outputId": "4c17fe07-fb8a-4a97-91cf-db6d3721c35a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "rooms_ind, bedrooms_ind, population_ind, households_ind = 3, 4, 5, 6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, add_bedrooms_per_room = True):\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        rooms_per_household = X[:, rooms_ind] / X[:, households_ind]\n",
        "        population_per_household = X[:, population_ind] / X[:, households_ind]\n",
        "        if self.add_bedrooms_per_room:\n",
        "            bedrooms_per_room = X[:, bedrooms_ind] / X[:, rooms_ind]\n",
        "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
        "        else:\n",
        "            return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "lr_pipeline = Pipeline([\n",
        "    ('attr_adder', CombinedAttributesAdder()),\n",
        "    ('std_scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "housing_extra_attribs = attr_adder.transform(X_train_whole.values)\n",
        "housing_trans = lr_pipeline.fit_transform(X_train_whole.values)\n",
        "lin_reg = LinearRegression()\n",
        "train_model(model=lin_reg, X=housing_trans)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
            "Accuracy: 0.64 +/- 0.01\n",
            "Time taken: 0.004478931427001953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7WiV4zJ3T-C",
        "colab_type": "text"
      },
      "source": [
        "<h3>Support Vector Machines</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLj55U293d1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svm_reg = LinearSVR(epsilon=1.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaH8Ix3R3iaW",
        "colab_type": "text"
      },
      "source": [
        "<h3>Neural Networks</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8wJoDLX3oAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.complie(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}